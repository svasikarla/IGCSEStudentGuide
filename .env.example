# IGCSE Study Guide - Environment Configuration
# Copy this file to .env and fill in your actual values

# =============================================================================
# DATABASE CONFIGURATION
# =============================================================================
SUPABASE_URL=your_supabase_project_url
SUPABASE_ANON_KEY=your_supabase_anon_key
SUPABASE_SERVICE_ROLE_KEY=your_supabase_service_role_key

# =============================================================================
# LLM PROVIDER CONFIGURATIONS
# =============================================================================

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key

# Google Gemini Configuration
GOOGLE_API_KEY=your_google_api_key

# Anthropic Claude Configuration
ANTHROPIC_API_KEY=your_anthropic_api_key

# Hugging Face Configuration (NEW)
# Get your token from: https://huggingface.co/settings/tokens
HF_TOKEN=your_hugging_face_token

# Azure OpenAI Configuration (Optional)
AZURE_OPENAI_API_KEY=your_azure_openai_key
AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint

# =============================================================================
# EMBEDDING PROVIDER CONFIGURATIONS
# =============================================================================

# Cohere Configuration (for embeddings)
COHERE_API_KEY=your_cohere_api_key

# =============================================================================
# APPLICATION CONFIGURATION
# =============================================================================

# Default LLM Provider (openai, google, anthropic, huggingface)
REACT_APP_DEFAULT_LLM_PROVIDER=openai

# Server Configuration
PORT=3001
NODE_ENV=development

# =============================================================================
# HUGGING FACE ROLLOUT CONFIGURATION
# =============================================================================

# Rollout percentage for Hugging Face (0-100)
HF_ROLLOUT_PERCENTAGE=10

# Enable gradual rollout monitoring
HF_ENABLE_MONITORING=true

# Enable fallback to other providers on HF failure
HF_ENABLE_FALLBACK=true

# Maximum retries before fallback
HF_MAX_RETRIES=2

# Fallback provider (openai, google, anthropic)
HF_FALLBACK_PROVIDER=openai

# =============================================================================
# COST MONITORING CONFIGURATION
# =============================================================================

# Enable cost tracking and monitoring
ENABLE_COST_MONITORING=true

# Cost alert threshold (USD per month)
COST_ALERT_THRESHOLD=50

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================

# JWT Secret for authentication
JWT_SECRET=your_jwt_secret_key

# Session secret
SESSION_SECRET=your_session_secret

# =============================================================================
# OPTIONAL CONFIGURATIONS
# =============================================================================

# Enable debug logging
DEBUG=false

# Enable detailed LLM request/response logging
LLM_DEBUG_LOGGING=false

# Rate limiting (requests per minute)
RATE_LIMIT_RPM=100

# =============================================================================
# DEPLOYMENT CONFIGURATION
# =============================================================================

# Frontend URL (for CORS)
FRONTEND_URL=http://localhost:3000

# Backend URL
BACKEND_URL=http://localhost:3001

# =============================================================================
# HUGGING FACE MODEL PREFERENCES
# =============================================================================

# Default Hugging Face model for different cost tiers
HF_MODEL_ULTRA_MINIMAL=meta-llama/Llama-3.1-8B-Instruct
HF_MODEL_MINIMAL=meta-llama/Llama-3.1-8B-Instruct
HF_MODEL_STANDARD=meta-llama/Llama-3.1-70B-Instruct
HF_MODEL_PREMIUM=meta-llama/Llama-3.1-70B-Instruct

# =============================================================================
# MONITORING AND ANALYTICS
# =============================================================================

# Enable performance monitoring
ENABLE_PERFORMANCE_MONITORING=true

# Enable error tracking
ENABLE_ERROR_TRACKING=true

# Analytics provider (optional)
ANALYTICS_PROVIDER=none

# =============================================================================
# EXAMPLE VALUES (DO NOT USE IN PRODUCTION)
# =============================================================================

# Example OpenAI API Key format:
# OPENAI_API_KEY=sk-proj-abcd1234...

# Example Hugging Face Token format:
# HF_TOKEN=hf_abcd1234...

# Example Google API Key format:
# GOOGLE_API_KEY=AIza...

# Example Supabase URL format:
# SUPABASE_URL=https://your-project.supabase.co

# =============================================================================
# SETUP INSTRUCTIONS
# =============================================================================

# 1. Copy this file to .env:
#    cp .env.example .env

# 2. Get your Hugging Face token:
#    - Visit https://huggingface.co/settings/tokens
#    - Create a new token with "Read" permissions
#    - Copy the token to HF_TOKEN above

# 3. Configure other LLM providers as needed:
#    - OpenAI: https://platform.openai.com/api-keys
#    - Google: https://makersuite.google.com/app/apikey
#    - Anthropic: https://console.anthropic.com/

# 4. Set up Supabase:
#    - Create a new project at https://supabase.com
#    - Copy the URL and anon key from Settings > API

# 5. Start with conservative rollout:
#    - Set HF_ROLLOUT_PERCENTAGE=10 initially
#    - Monitor performance and gradually increase

# 6. Enable monitoring:
#    - Set ENABLE_COST_MONITORING=true
#    - Set HF_ENABLE_MONITORING=true
#    - Review logs and metrics regularly

# =============================================================================
# COST OPTIMIZATION TIPS
# =============================================================================

# For maximum cost savings:
# - Use HF_ROLLOUT_PERCENTAGE=100 after successful testing
# - Set REACT_APP_DEFAULT_LLM_PROVIDER=huggingface
# - Use ultra_minimal cost tier for most generations
# - Monitor actual costs vs projections

# For reliability:
# - Keep HF_ENABLE_FALLBACK=true
# - Set HF_FALLBACK_PROVIDER to a reliable provider
# - Monitor error rates and adjust rollout accordingly
